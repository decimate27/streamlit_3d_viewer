"""
ì›¹ì„œë²„ DBì™€ ë¡œì»¬ DB ë™ê¸°í™” ëª¨ë“ˆ
ì›¹ì„œë²„ì˜ streamlit_3d.dbë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ DBì™€ ë™ê¸°í™”í•©ë‹ˆë‹¤.
"""

import sqlite3
import requests
import tempfile
import os
import json
import streamlit as st
from datetime import datetime
import shutil

class WebDBSync:
    def __init__(self):
        # ì›¹ì„œë²„ì˜ DB ì§ì ‘ ì ‘ê·¼ URL
        self.web_db_url = "https://www.airbible.kr/streamlit_data/streamlit_3d.db"
        # API ëŒ€ì²´ URL (DB ì§ì ‘ ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ)
        self.api_base_url = "https://www.airbible.kr/streamlit_data"
        self.get_models_url = f"{self.api_base_url}/get_all_models.php"
        self.local_db_path = "data/models.db"
        self.temp_db_path = None
        
    def download_web_db(self):
        """ì›¹ì„œë²„ì—ì„œ DB íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            st.info("ðŸŒ ì›¹ì„œë²„ DB ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # ìž„ì‹œ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp_file:
                self.temp_db_path = tmp_file.name
                
                # í—¤ë” ì¶”ê°€í•˜ì—¬ DB íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': '*/*',
                    'Referer': 'https://www.airbible.kr/'
                }
                
                response = requests.get(self.web_db_url, headers=headers, timeout=30, verify=False)
                response.raise_for_status()
                
                tmp_file.write(response.content)
                
            st.success(f"âœ… ì›¹ì„œë²„ DB ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (í¬ê¸°: {len(response.content):,} bytes)")
            return True
            
        except requests.exceptions.RequestException as e:
            st.warning(f"âš ï¸ DB ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, API ì‚¬ìš© ì‹œë„ ì¤‘...")
            # APIë¥¼ í†µí•œ ëŒ€ì²´ ë°©ë²• ì‹œë„
            return self.download_via_api()
        except Exception as e:
            st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def download_via_api(self):
        """APIë¥¼ í†µí•´ ëª¨ë¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ëŒ€ì²´ ë°©ë²•)"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/json'
            }
            
            response = requests.get(self.get_models_url, headers=headers, timeout=30, verify=False)
            
            if response.status_code == 200:
                data = response.json()
                if data.get('status') == 'success':
                    self.web_models_data = data.get('models', [])
                    st.success(f"âœ… APIë¥¼ í†µí•´ {len(self.web_models_data)}ê°œ ëª¨ë¸ ì •ë³´ ìˆ˜ì‹ ")
                    return True
            
            st.error("âŒ API ì‘ë‹µ ì˜¤ë¥˜")
            return False
            
        except Exception as e:
            st.error(f"âŒ API ì ‘ê·¼ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def analyze_databases(self):
        """ë¡œì»¬ DBì™€ ì›¹ì„œë²„ DB ë¹„êµ ë¶„ì„"""
        if not self.temp_db_path or not os.path.exists(self.temp_db_path):
            st.error("ì›¹ì„œë²„ DBê°€ ë‹¤ìš´ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        analysis = {
            'local_models': [],
            'web_models': [],
            'missing_models': [],
            'local_count': 0,
            'web_count': 0,
            'sync_needed': False
        }
        
        try:
            # ë¡œì»¬ DB ë¶„ì„
            if os.path.exists(self.local_db_path):
                conn_local = sqlite3.connect(self.local_db_path)
                cursor_local = conn_local.cursor()
                
                cursor_local.execute("SELECT id, name, author, created_at FROM models")
                local_models = cursor_local.fetchall()
                analysis['local_models'] = local_models
                analysis['local_count'] = len(local_models)
                
                local_ids = set(model[0] for model in local_models)
                conn_local.close()
            else:
                local_ids = set()
                
            # ì›¹ì„œë²„ DB ë¶„ì„
            conn_web = sqlite3.connect(self.temp_db_path)
            cursor_web = conn_web.cursor()
            
            cursor_web.execute("SELECT id, name, author, created_at FROM models ORDER BY created_at")
            web_models = cursor_web.fetchall()
            analysis['web_models'] = web_models
            analysis['web_count'] = len(web_models)
            
            # ëˆ„ë½ëœ ëª¨ë¸ ì°¾ê¸°
            for model in web_models:
                if model[0] not in local_ids:
                    analysis['missing_models'].append(model)
                    
            analysis['sync_needed'] = len(analysis['missing_models']) > 0
            conn_web.close()
            
            return analysis
            
        except Exception as e:
            st.error(f"âŒ DB ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def convert_web_to_local_format(self, web_data):
        """ì›¹ì„œë²„ DB í˜•ì‹ì„ ë¡œì»¬ DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        # ì›¹ì„œë²„ DB ìŠ¤í‚¤ë§ˆ:
        # id, name, author, description, share_token, obj_path, mtl_path, texture_paths, storage_type, access_count, created_at
        
        # ë¡œì»¬ DB ìŠ¤í‚¤ë§ˆ:
        # id, name, author, description, file_paths, backup_paths, storage_type, share_token, created_at, last_accessed, access_count, real_height
        
        id_val = web_data[0]
        name = web_data[1]
        author = web_data[2]
        description = web_data[3]
        share_token = web_data[4]
        obj_path = web_data[5]
        mtl_path = web_data[6]
        texture_paths = web_data[7]
        storage_type = web_data[8] or 'web'
        access_count = web_data[9]
        created_at = web_data[10]
        
        # file_paths JSON ìƒì„± (ì›¹ì„œë²„ ê²½ë¡œ í˜•ì‹)
        file_paths = {
            "obj_path": f"{id_val}/model.obj",
            "mtl_path": f"{id_val}/model.mtl",
            "texture_paths": []
        }
        
        # í…ìŠ¤ì²˜ ê²½ë¡œ ì²˜ë¦¬
        if texture_paths:
            try:
                # JSON í˜•ì‹ì¸ ê²½ìš°
                if texture_paths.startswith('['):
                    texture_list = json.loads(texture_paths)
                else:
                    # ë‹¨ì¼ ê²½ë¡œì¸ ê²½ìš°
                    texture_list = [texture_paths]
                    
                for tex_path in texture_list:
                    # files/ ê²½ë¡œ ì œê±°í•˜ê³  ëª¨ë¸ ID ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    if 'files/' in tex_path:
                        # files/model_id/texture.png -> model_id/texture.png
                        clean_path = tex_path.replace('files/', '')
                    else:
                        clean_path = tex_path
                    
                    # íŒŒì¼ëª…ë§Œ ì¶”ì¶œí•˜ì—¬ ê²½ë¡œ êµ¬ì„±
                    filename = os.path.basename(clean_path)
                    if filename:
                        file_paths["texture_paths"].append(f"{id_val}/{filename}")
            except:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
                pass
        
        # backup_paths JSON ìƒì„± (ë¡œì»¬ ë°±ì—… ê²½ë¡œ)
        backup_paths = {
            "obj_path": f"data/models/{id_val}/model.obj",
            "mtl_path": f"data/models/{id_val}/model.mtl",
            "texture_paths": []
        }
        
        for tex_path in file_paths["texture_paths"]:
            filename = os.path.basename(tex_path)
            if filename:
                backup_paths["texture_paths"].append(f"data/models/{id_val}/{filename}")
        
        return (
            id_val,
            name,
            author,
            description,
            json.dumps(file_paths),
            json.dumps(backup_paths),
            storage_type,
            share_token,
            created_at,
            None,  # last_accessed
            access_count,
            1.0    # real_height (ê¸°ë³¸ê°’)
        )
    
    def sync_databases(self, show_progress=True):
        """ì›¹ì„œë²„ DBì™€ ë¡œì»¬ DB ë™ê¸°í™”"""
        try:
            # 1. ì›¹ì„œë²„ DB ë‹¤ìš´ë¡œë“œ
            if not self.download_web_db():
                return False
                
            # 2. DB ë¶„ì„
            analysis = self.analyze_databases()
            if not analysis:
                return False
                
            # 3. ë™ê¸°í™” ìƒíƒœ í‘œì‹œ
            if show_progress:
                st.write("ðŸ“Š **ë™ê¸°í™” ë¶„ì„ ê²°ê³¼:**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ë¡œì»¬ DB", f"{analysis['local_count']}ê°œ ëª¨ë¸")
                with col2:
                    st.metric("ì›¹ì„œë²„ DB", f"{analysis['web_count']}ê°œ ëª¨ë¸")
                with col3:
                    st.metric("ë³µêµ¬ í•„ìš”", f"{len(analysis['missing_models'])}ê°œ ëª¨ë¸")
            
            # 4. ë™ê¸°í™” í•„ìš” ì—†ìœ¼ë©´ ì¢…ë£Œ
            if not analysis['sync_needed']:
                st.success("âœ… ì´ë¯¸ ë™ê¸°í™”ëœ ìƒíƒœìž…ë‹ˆë‹¤.")
                return True
                
            # 5. ëˆ„ë½ëœ ëª¨ë¸ ë³µêµ¬
            if show_progress:
                st.info(f"ðŸ”„ {len(analysis['missing_models'])}ê°œ ëª¨ë¸ ë³µêµ¬ ì¤‘...")
                
            # ì›¹ì„œë²„ DBì—ì„œ ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            conn_web = sqlite3.connect(self.temp_db_path)
            cursor_web = conn_web.cursor()
            
            cursor_web.execute("""
                SELECT id, name, author, description, share_token, 
                       obj_path, mtl_path, texture_paths, storage_type, 
                       access_count, created_at 
                FROM models
                WHERE id IN ({})
            """.format(','.join(['?'] * len(analysis['missing_models']))),
                [model[0] for model in analysis['missing_models']])
            
            missing_data = cursor_web.fetchall()
            conn_web.close()
            
            # ë¡œì»¬ DBì— ì‚½ìž…
            conn_local = sqlite3.connect(self.local_db_path)
            cursor_local = conn_local.cursor()
            
            recovered_count = 0
            for web_data in missing_data:
                try:
                    # ë°ì´í„° í˜•ì‹ ë³€í™˜
                    local_data = self.convert_web_to_local_format(web_data)
                    
                    # ë¡œì»¬ DBì— ì‚½ìž…
                    cursor_local.execute("""
                        INSERT OR IGNORE INTO models (
                            id, name, author, description, file_paths, backup_paths,
                            storage_type, share_token, created_at, last_accessed, 
                            access_count, real_height
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, local_data)
                    
                    if show_progress:
                        st.success(f"âœ… ë³µêµ¬: {web_data[1]} by {web_data[2]}")
                    recovered_count += 1
                    
                except Exception as e:
                    st.error(f"âŒ ë³µêµ¬ ì‹¤íŒ¨: {web_data[1]} - {str(e)}")
            
            conn_local.commit()
            conn_local.close()
            
            # 6. ê²°ê³¼ í‘œì‹œ
            if show_progress:
                st.success(f"ðŸŽ‰ ë™ê¸°í™” ì™„ë£Œ! {recovered_count}ê°œ ëª¨ë¸ì´ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            return True
            
        except Exception as e:
            st.error(f"âŒ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
            
        finally:
            # ìž„ì‹œ íŒŒì¼ ì •ë¦¬
            if self.temp_db_path and os.path.exists(self.temp_db_path):
                try:
                    os.remove(self.temp_db_path)
                except:
                    pass
    
    def quick_sync_check(self):
        """ë¹ ë¥¸ ë™ê¸°í™” í•„ìš” ì—¬ë¶€ í™•ì¸ (UI í‘œì‹œ ì—†ìŒ)"""
        try:
            # ì›¹ì„œë²„ DB ë‹¤ìš´ë¡œë“œ (ì¡°ìš©ížˆ)
            response = requests.get(self.web_db_url, timeout=10)
            if response.status_code != 200:
                return False
                
            # ìž„ì‹œ íŒŒì¼ì— ì €ìž¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp_file:
                tmp_path = tmp_file.name
                tmp_file.write(response.content)
            
            # ì›¹ì„œë²„ DB ëª¨ë¸ ìˆ˜ í™•ì¸
            conn_web = sqlite3.connect(tmp_path)
            cursor_web = conn_web.cursor()
            cursor_web.execute("SELECT COUNT(*) FROM models")
            web_count = cursor_web.fetchone()[0]
            conn_web.close()
            
            # ë¡œì»¬ DB ëª¨ë¸ ìˆ˜ í™•ì¸
            local_count = 0
            if os.path.exists(self.local_db_path):
                conn_local = sqlite3.connect(self.local_db_path)
                cursor_local = conn_local.cursor()
                cursor_local.execute("SELECT COUNT(*) FROM models")
                local_count = cursor_local.fetchone()[0]
                conn_local.close()
            
            # ìž„ì‹œ íŒŒì¼ ì‚­ì œ
            os.remove(tmp_path)
            
            # ë™ê¸°í™” í•„ìš” ì—¬ë¶€ ë°˜í™˜
            return web_count > local_count
            
        except:
            return False